{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Environment import GridworldEnv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "origin: (2, 3, 4)\nno axis: ()\naxis=0: (3, 4)\naxis=1: (2, 4)\naxis=2: (2, 3)\n"
    }
   ],
   "source": [
    "a = np.arange(24).reshape(2,3,4)\n",
    "print(\"origin:\",a.shape) # (3, 4)\n",
    "print(\"no axis:\",np.max(a).shape) # (1)\n",
    "print(\"axis=0:\",np.max(a, axis=0).shape) # (4)\n",
    "print(\"axis=1:\",np.max(a, axis=1).shape) # (3)\n",
    "print(\"axis=2:\",np.max(a, axis=2).shape) # (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_action_values(environment, state, state_values, discount= 1.0):\n",
    "    \"对某一状态而言的动作价值函数\"\n",
    "    env = environment\n",
    "    \"初始化动作价值函数\"\n",
    "    action_values = np.zeros((env.nA), dtype=np.float32)\n",
    "    for action in range(env.nA):\n",
    "        for prob, next_state, reward, done in env.P[state][action]:\n",
    "            action_values[action] += prob * (reward + discount * state_values[next_state])\n",
    "    \n",
    "    return action_values # (env.nA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(environment, theta = 1e-1, discount = 1.0):\n",
    "    env = environment\n",
    "    \"初始化状态价值函数\"\n",
    "    state_values = np.zeros((env.nS), dtype=np.float32)\n",
    "    max_eposides = 50\n",
    "    \n",
    "    \"值迭代核心算法\"\n",
    "    for eposide in range(max_eposides):\n",
    "        delta = 0.\n",
    "        \"对每一状态迭代\"\n",
    "        for state in range(env.nS):\n",
    "            action_values = cal_action_values(env, state, state_values, discount) # (nA)\n",
    "            optim_action_values = np.max(action_values)\n",
    "            delta = np.maximum(delta, np.abs(optim_action_values - state_values[state]))\n",
    "            state_values[state] = optim_action_values\n",
    "\n",
    "        # print(\"eposide:\", eposide, \"state_values\",state_values, \"\\n\")\n",
    "        if(delta <= theta):\n",
    "            break\n",
    "    \n",
    "    \"策略评估\"\n",
    "    optim_policy = np.zeros((env.nS, env.nA), dtype=np.float32)\n",
    "    for state in range(env.nS):\n",
    "        action_values = cal_action_values(env, state, state_values, discount) # (nA)\n",
    "        optim_action = np.argmax(action_values)\n",
    "        optim_policy[state, optim_action] = 1.\n",
    "    return optim_policy, state_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1 1 2 3]\n [2 0 2 0]\n [1 1 2 0]\n [0 1 1 0]]\n[[ -6.  -5.  -4.  -5.]\n [ -5. -50.  -3. -50.]\n [ -4.  -3.  -2. -50.]\n [-50.  -2.  -1.   0.]]\n"
    }
   ],
   "source": [
    "env = GridworldEnv()\n",
    "policy, state_values = value_iteration(env) # (nS, nA), (nS)\n",
    "print(np.argmax(policy, axis=1).reshape(env.desc.shape))\n",
    "print(state_values.reshape(env.desc.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38464bit48db41c0f43d45c882ae1cd0cd1553ec",
   "display_name": "Python 3.8.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}